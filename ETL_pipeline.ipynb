{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comebine the data into a single database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_tweet_data(df, db_path, append=True):\n",
    "    \n",
    "    conn = sqlite3.connect(db_path)\n",
    "    if append:\n",
    "        df.to_sql('tweets', con = conn, if_exists='append', index=False)\n",
    "    else:\n",
    "        df.to_sql('tweets', con = conn, if_exists='replace', index=False)\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute this code cell to run the ETL pipeline\n",
    "\n",
    "\n",
    "# Extract\n",
    "\n",
    "PATHS_TO_DATA = ['data/disaster_response_messages_training.csv',\n",
    "                 'data/disaster_response_messages_test.csv',\n",
    "                 'data/disaster_response_messages_validation.csv'\n",
    "                ]\n",
    "\n",
    "df = pd.DataFrame()\n",
    "for path in PATHS_TO_DATA:\n",
    "    df_part = pd.read_csv(path)\n",
    "    if df.empty:\n",
    "        df = df_part\n",
    "    else:\n",
    "        df = pd.merge(df, df_part, how='outer')\n",
    "    \n",
    "# Transform\n",
    "\n",
    "# Drop columns where every entry is the same\n",
    "for col in df:\n",
    "    if df[col].value_counts().shape[0] == 1:\n",
    "        df.drop(columns=col, inplace=True)\n",
    "\n",
    "# Drop the split column\n",
    "df.drop(columns='split', inplace=True)\n",
    "        \n",
    "# The related column has a few tweets that are labeled as a 2 instead of a 1 or zero, drop these.\n",
    "df = df[df['related'] != 2]\n",
    "\n",
    "# Load\n",
    "\n",
    "DB_PATH = 'data/disaster_tweets.db'\n",
    "load_tweet_data(df, DB_PATH, append=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26055, 39)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn = sqlite3.connect(db_path)\n",
    "\n",
    "pd.read_sql('SELECT * FROM tweets', con = conn).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
