{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a model with the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "import pickle\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('../data/disaster_tweets.db')\n",
    "df = pd.read_sql('SELECT * FROM tweets', con = conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'message', 'original', 'genre', 'related', 'PII', 'request',\n",
       "       'offer', 'aid_related', 'medical_help', 'medical_products',\n",
       "       'search_and_rescue', 'security', 'military', 'child_alone', 'water',\n",
       "       'food', 'shelter', 'clothing', 'money', 'missing_people', 'refugees',\n",
       "       'death', 'other_aid', 'infrastructure_related', 'transport',\n",
       "       'buildings', 'electricity', 'tools', 'hospitals', 'shops',\n",
       "       'aid_centers', 'other_infrastructure', 'weather_related', 'floods',\n",
       "       'storm', 'fire', 'earthquake', 'cold', 'other_weather',\n",
       "       'direct_report'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['message']\n",
    "Y = df[['related','request',\n",
    "       'offer', 'aid_related', 'medical_help', 'medical_products',\n",
    "       'search_and_rescue', 'security', 'military', 'water',\n",
    "       'food', 'shelter', 'clothing', 'money', 'missing_people', 'refugees',\n",
    "       'death', 'other_aid', 'infrastructure_related', 'transport',\n",
    "       'buildings', 'electricity', 'tools', 'hospitals', 'shops',\n",
    "       'aid_centers', 'other_infrastructure', 'weather_related', 'floods',\n",
    "       'storm', 'fire', 'earthquake', 'cold', 'other_weather',\n",
    "       'direct_report']]\n",
    "\n",
    "category_names = list(Y.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are disaster related messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weather update - a cold front from Cuba that could pass over Haiti\n",
      "\n",
      "Is the Hurricane over or is it not over\n",
      "\n",
      "says: west side of Haiti, rest of the country today and tonight\n",
      "\n",
      "Storm at sacred heart of jesus\n",
      "\n",
      "Please, we need tents and water. We are in Silo, Thank you!\n",
      "\n",
      "There's nothing to eat and water, we starving and thirsty.\n",
      "\n",
      "I am in Thomassin number 32, in the area named Pyron. I would like to have some water. Thank God we are fine, but we desperately need water. Thanks\n",
      "\n",
      "Let's do it together, need food in Delma 75, in didine area\n",
      "\n",
      "More information on the 4636 number in order for me to participate. ( To see if I can use it )\n",
      "\n",
      "A Comitee in Delmas 19, Rue ( street ) Janvier, Impasse Charite #2. We have about 500 people in a temporary shelter and we are in dire need of Water, Food, Medications, Tents and Clothes. Please stop by and see us.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(X[Y['related'] == 1].iloc[i] + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are non-disaster related messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information about the National Palace-\n",
      "\n",
      "I would like to receive the messages, thank you\n",
      "\n",
      "I am in Petionville. I need more information regarding 4636\n",
      "\n",
      "I don't understand how to use this thing 4636.\n",
      "\n",
      "Can you tell me about this service\n",
      "\n",
      "Good evening, Radio one please. I would like information on Tiyous.\n",
      "\n",
      "I'm here, I didn't find the person that I needed to send the pant by phone\n",
      "\n",
      "I'm listening to you at Miraguan we asking the government to take change because one gallon gas is 80.\n",
      "\n",
      "i am very happy, i hear god, religious hyme\n",
      "\n",
      "I would like to know how food is distributed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(X[Y['related'] == 0].iloc[i] + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "porter = PorterStemmer()\n",
    "def tokenize(text):\n",
    "    return [porter.stem(word) for word in text.split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer(tokenizer = tokenize)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', MultiOutputClassifier(LogisticRegression(class_weight='balanced',multi_class='ovr')))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andrewblaikie/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('vect',\n",
       "                 CountVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=1.0,\n",
       "                                 max_features=None, min_df=1,\n",
       "                                 ngram_range=(1, 1), preprocessor=None,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=<function tokenize at...\n",
       "                 TfidfTransformer(norm='l2', smooth_idf=True,\n",
       "                                  sublinear_tf=False, use_idf=True)),\n",
       "                ('clf',\n",
       "                 MultiOutputClassifier(estimator=LogisticRegression(C=1.0,\n",
       "                                                                    class_weight='balanced',\n",
       "                                                                    dual=False,\n",
       "                                                                    fit_intercept=True,\n",
       "                                                                    intercept_scaling=1,\n",
       "                                                                    l1_ratio=None,\n",
       "                                                                    max_iter=100,\n",
       "                                                                    multi_class='ovr',\n",
       "                                                                    n_jobs=None,\n",
       "                                                                    penalty='l2',\n",
       "                                                                    random_state=None,\n",
       "                                                                    solver='lbfgs',\n",
       "                                                                    tol=0.0001,\n",
       "                                                                    verbose=0,\n",
       "                                                                    warm_start=False),\n",
       "                                       n_jobs=None))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category: related \n",
      "f1 Score: 0.8609711651838353 \n",
      "Accuracy 0.8008903899293829\n",
      "\n",
      "\n",
      "Category: request \n",
      "f1 Score: 0.6702168124762267 \n",
      "Accuracy 0.8669020571077679\n",
      "\n",
      "\n",
      "Category: offer \n",
      "f1 Score: 0.05042016806722689 \n",
      "Accuracy 0.9826527479275406\n",
      "\n",
      "\n",
      "Category: aid_related \n",
      "f1 Score: 0.7396333867236163 \n",
      "Accuracy 0.7754068160884249\n",
      "\n",
      "\n",
      "Category: medical_help \n",
      "f1 Score: 0.422972972972973 \n",
      "Accuracy 0.8688977586736261\n",
      "\n",
      "\n",
      "Category: medical_products \n",
      "f1 Score: 0.39840637450199207 \n",
      "Accuracy 0.907276634940129\n",
      "\n",
      "\n",
      "Category: search_and_rescue \n",
      "f1 Score: 0.2473867595818815 \n",
      "Accuracy 0.933681301811483\n",
      "\n",
      "\n",
      "Category: security \n",
      "f1 Score: 0.11176470588235295 \n",
      "Accuracy 0.9536383174700644\n",
      "\n",
      "\n",
      "Category: military \n",
      "f1 Score: 0.45973154362416113 \n",
      "Accuracy 0.9505680073687442\n",
      "\n",
      "\n",
      "Category: water \n",
      "f1 Score: 0.6482504604051565 \n",
      "Accuracy 0.9413570770647836\n",
      "\n",
      "\n",
      "Category: food \n",
      "f1 Score: 0.7079326923076923 \n",
      "Accuracy 0.9253914645379183\n",
      "\n",
      "\n",
      "Category: shelter \n",
      "f1 Score: 0.5990271021542738 \n",
      "Accuracy 0.9114215535769112\n",
      "\n",
      "\n",
      "Category: clothing \n",
      "f1 Score: 0.4367816091954023 \n",
      "Accuracy 0.9774332207552963\n",
      "\n",
      "\n",
      "Category: money \n",
      "f1 Score: 0.4116424116424116 \n",
      "Accuracy 0.9565551120663187\n",
      "\n",
      "\n",
      "Category: missing_people \n",
      "f1 Score: 0.19090909090909092 \n",
      "Accuracy 0.9726742400982499\n",
      "\n",
      "\n",
      "Category: refugees \n",
      "f1 Score: 0.38179148311306904 \n",
      "Accuracy 0.9353699723672091\n",
      "\n",
      "\n",
      "Category: death \n",
      "f1 Score: 0.5320197044334976 \n",
      "Accuracy 0.9416641080749155\n",
      "\n",
      "\n",
      "Category: other_aid \n",
      "f1 Score: 0.4400785854616896 \n",
      "Accuracy 0.7812404052809334\n",
      "\n",
      "\n",
      "Category: infrastructure_related \n",
      "f1 Score: 0.2998624484181568 \n",
      "Accuracy 0.8437212158428001\n",
      "\n",
      "\n",
      "Category: transport \n",
      "f1 Score: 0.3075117370892019 \n",
      "Accuracy 0.9094258520110531\n",
      "\n",
      "\n",
      "Category: buildings \n",
      "f1 Score: 0.48636859323882226 \n",
      "Accuracy 0.9276941971139085\n",
      "\n",
      "\n",
      "Category: electricity \n",
      "f1 Score: 0.4152046783625731 \n",
      "Accuracy 0.9692968989867977\n",
      "\n",
      "\n",
      "Category: tools \n",
      "f1 Score: 0.09999999999999999 \n",
      "Accuracy 0.986183604544059\n",
      "\n",
      "\n",
      "Category: hospitals \n",
      "f1 Score: 0.24390243902439027 \n",
      "Accuracy 0.9762050967147682\n",
      "\n",
      "\n",
      "Category: shops \n",
      "f1 Score: 0.07547169811320754 \n",
      "Accuracy 0.9924777402517654\n",
      "\n",
      "\n",
      "Category: aid_centers \n",
      "f1 Score: 0.2230769230769231 \n",
      "Accuracy 0.9689898679766656\n",
      "\n",
      "\n",
      "Category: other_infrastructure \n",
      "f1 Score: 0.27027027027027023 \n",
      "Accuracy 0.8839422781700952\n",
      "\n",
      "\n",
      "Category: weather_related \n",
      "f1 Score: 0.7610619469026548 \n",
      "Accuracy 0.8632176849861836\n",
      "\n",
      "\n",
      "Category: floods \n",
      "f1 Score: 0.5670186839967506 \n",
      "Accuracy 0.9181762357998158\n",
      "\n",
      "\n",
      "Category: storm \n",
      "f1 Score: 0.6800862688713156 \n",
      "Accuracy 0.9316856002456249\n",
      "\n",
      "\n",
      "Category: fire \n",
      "f1 Score: 0.3766233766233766 \n",
      "Accuracy 0.9852625115136628\n",
      "\n",
      "\n",
      "Category: earthquake \n",
      "f1 Score: 0.7953488372093024 \n",
      "Accuracy 0.9594719066625729\n",
      "\n",
      "\n",
      "Category: cold \n",
      "f1 Score: 0.5044510385756676 \n",
      "Accuracy 0.9743629106539761\n",
      "\n",
      "\n",
      "Category: other_weather \n",
      "f1 Score: 0.32413178984861973 \n",
      "Accuracy 0.8834817316548972\n",
      "\n",
      "\n",
      "Category: direct_report \n",
      "f1 Score: 0.62891809908999 \n",
      "Accuracy 0.8309794289223211\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate the accuracy for each of them.\n",
    "for i in range(len(category_names)):\n",
    "    print('Category: {} '.format(category_names[i]))\n",
    "    print('f1 Score: {} '.format(f1_score(Y_test.iloc[:, i].values, Y_pred[:, i])))\n",
    "    print('Accuracy {}\\n\\n'.format(accuracy_score(Y_test.iloc[:, i].values, Y_pred[:, i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(pipeline, open('trained_classifier.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model from pickle file\n",
    "\n",
    "model = pickle.load(open('trained_classifier.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predicted_category_names(category_predicted):\n",
    "    return [category_names[i] for i in range(len(category_predicted)) if category_predicted[i] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['related', 'request', 'water', 'weather_related', 'storm', 'direct_report']"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_predicted_category_names(model.predict([\"I felt a big storm in Eugene this morning. I need water.\"])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_predicted_category_names(model.predict([\"How do I download zoom for this remote meeting?\"])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
